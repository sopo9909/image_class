{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eH2IZ1rWbB2d"
   },
   "source": [
    "참조 URL : https://github.com/eriklindernoren/PyTorch-YOLOv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cd0SKpgLSonG"
   },
   "source": [
    "# 필요한 Library 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0LD-fkJ2wQsV",
    "outputId": "311a5643-3ad0-4010-91a0-b2981b2fec8f"
   },
   "outputs": [],
   "source": [
    "# PyTorch에서 구현된 YOLOv3 코드 및 데이터를 git을 이용하여 복사\n",
    "!git clone https://github.com/eriklindernoren/PyTorch-YOLOv3\n",
    "\n",
    "# darknet, YOLOv3, YOLOv3-tiny의 weight를 bash를 이용하여 다운로드\n",
    "!bash ./PyTorch-YOLOv3/weights/download_weights.sh\n",
    "\n",
    "# 구현된 라이브러리 설치\n",
    "!pip3 install pytorchyolo\n",
    "\n",
    "# 라이브러리 설치 시 Pytorch 버전과 torchvision 버전이 맞지 않는 이슈 발생\n",
    "# torchvision을 다시 설치하면 Pytorch와 torchvision 버전이 맞춰짐\n",
    "!pip3 install torchvision\n",
    "\n",
    "### 해당 셀 실행 종료 후 런타임 재시작 (Pillow, Matplotlib 최신 버전 사용 시 런타임 재시작 필요) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3QDni7wSeb6"
   },
   "source": [
    "# Inference 및 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DEk2R-rVxZDj"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import pytorchyolo\n",
    "from pytorchyolo import detect, models\n",
    "from pytorchyolo.utils.utils import load_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlCfWZsJxfZH"
   },
   "outputs": [],
   "source": [
    "# YOLO model 불러오기\n",
    "# yolov3.cfg 파일과 yolov3.weights 파일의 경로를 확인 후 입력\n",
    "model = models.load_model(\n",
    "  \"./PyTorch-YOLOv3/config/yolov3.cfg\", \n",
    "  \"./yolov3.weights\"\n",
    "  )\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Dataset의 class name 불러오기\n",
    "# coco.names 파일의 경로를 확인 후 입력\n",
    "classes = load_classes('./PyTorch-YOLOv3/data/coco.names')\n",
    "\n",
    "# 시각화를 위해 각 클래스 별 color 설정\n",
    "bs = np.random.choice( np.arange(256), size=len(classes), replace=False )\n",
    "gs = np.random.choice( np.arange(256), size=len(classes), replace=False )\n",
    "rs = np.random.choice( np.arange(256), size=len(classes), replace=False )\n",
    "\n",
    "cls_color = {}\n",
    "for class_name, b, g, r in zip(classes, bs, gs, rs):\n",
    "    cls_color[class_name] = (int(b), int(g), int(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "UD6YVdtJxf4X",
    "outputId": "36a39b00-a709-4549-cec5-28edb8f53d47"
   },
   "outputs": [],
   "source": [
    "# git으로 받은 폴더 내에 있는 이미지 불러오기\n",
    "# 입력할 이미지의 경로를 확인 후 입력\n",
    "img = cv2.imread(\"./PyTorch-YOLOv3/data/samples/dog.jpg\")\n",
    "\n",
    "# 불러온 이미지 확인\n",
    "plt.figure( figsize=(10,10) )\n",
    "plt.imshow( img[..., ::-1] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "no5YV8tKxgFn",
    "outputId": "a769d96d-3d57-45e5-e50f-54b2c3c0891e"
   },
   "outputs": [],
   "source": [
    "# Detection\n",
    "# boxes = NMS를 적용한 결과 (x1, y1, x2, y2, confidence, class)\n",
    "boxes = detect.detect_image(model, img)\n",
    "\n",
    "# Detection 결과 확인\n",
    "print('Result Shape :', boxes.shape)\n",
    "print('Result :\\n', boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "EwdxXNFxymsG",
    "outputId": "4a9c09e4-81c7-49fa-df59-f34579d5cef4"
   },
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "plot_image = img.copy()\n",
    "\n",
    "for (x1, y1, x2, y2, confidence, cls) in boxes:\n",
    "\n",
    "    class_name = classes[ int(cls) ]\n",
    "\n",
    "    b, g, r = cls_color[class_name]\n",
    "\n",
    "    text = f'{class_name} : {confidence:.2f}'\n",
    "    size, baseline = cv2.getTextSize( text, 4, 0.9, 2 )\n",
    "    cv2.putText( plot_image, text, (int(x2-size[0]), int(y2+size[1])), 4, 0.9, (b, g, r), 2 )\n",
    "\n",
    "    cv2.rectangle( plot_image, (int(x1), int(y1)), (int(x2), int(y2)), (b, g, r), 2 )\n",
    "\n",
    "plt.figure( figsize=(10,10) )\n",
    "plt.imshow( plot_image[..., ::-1] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUQjquQgSvQV"
   },
   "source": [
    "# 모델 구조 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qH72GDhAyyTl",
    "outputId": "5cc8d23a-6eac-4b28-dae2-814485e5b23f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytorchyolo\n",
    "from pytorchyolo import models\n",
    "from pytorchyolo.utils.parse_config import parse_model_config\n",
    "\n",
    "### 모델 구조 확인 ###\n",
    "model = models.load_model(\n",
    "  \"./PyTorch-YOLOv3/config/yolov3.cfg\", \n",
    "  \"./yolov3.weights\"\n",
    ")\n",
    "\n",
    "# pytorch에서는 .eval()을 사용하면 train parameter(dropout, batchnorm 등)를 사용하지 않도록 설정됨\n",
    "# 또한 셀에서 .eval() 사용 시 모델 구조를 출력하는 기능도 포함되어 있음\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JlirH2H8j6_"
   },
   "source": [
    "#### 모델 구현 코드 URL\n",
    "- https://github.com/eriklindernoren/PyTorch-YOLOv3/blob/master/pytorchyolo/models.py\n",
    "\n",
    "#### cfg 파일 확인\n",
    "- https://github.com/eriklindernoren/PyTorch-YOLOv3/blob/master/config/yolov3.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6WrRvJ2pTl1m",
    "outputId": "f4e27679-a133-4e58-828f-0f5ecfadbc8d"
   },
   "outputs": [],
   "source": [
    "# cfg 파일을 parsing하여 모델 구조를 생성함\n",
    "module_defs = parse_model_config(\"./PyTorch-YOLOv3/config/yolov3.cfg\") # cfg 파일을 parsing 하는 함수\n",
    "\n",
    "for module_def in module_defs:\n",
    "    print( module_def )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 parameter의 name과 weight를 확인할 수 있음\n",
    "# 필요에 따라 requires_grad 를 False로 설정하여 freeze\n",
    "for name, param in model.named_parameters:\n",
    "    print( f\"{name} : {param.shape} ({param.requires_grad})\" )\n",
    "    # if name == '???'\n",
    "    #     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rwvkrpmDB_0"
   },
   "source": [
    "# NMS 적용 소스 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIRhFkP1TnZu"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "### x, y, w, h => x1, y1, x2, y2 변환 ###\n",
    "def xywh2xyxy(x):\n",
    "    y = x.new(x.shape)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n",
    "\n",
    "### Non-maximum suppression 구현 코드 (Github 참조) ###\n",
    "def non_max_suppression(prediction, conf_thres=0.25, iou_thres=0.45, classes=None):\n",
    "    \"\"\"Performs Non-Maximum Suppression (NMS) on inference results\n",
    "    Returns:\n",
    "         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)\n",
    "    \"\"\"\n",
    "\n",
    "    nc = prediction.shape[2] - 5  # number of classes\n",
    "\n",
    "    # Settings\n",
    "    # (pixels) minimum and maximum box width and height\n",
    "    max_wh = 4096\n",
    "    max_det = 300  # maximum number of detections per image\n",
    "    max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()\n",
    "    time_limit = 1.0  # seconds to quit after\n",
    "    multi_label = nc > 1  # multiple labels per box (adds 0.5ms/img)\n",
    "\n",
    "    t = time.time()\n",
    "    output = [torch.zeros((0, 6), device=prediction.device)] * prediction.shape[0]\n",
    "\n",
    "    for xi, x in enumerate(prediction):  # image index, image inference\n",
    "        # Apply constraints\n",
    "        # x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height\n",
    "        x = x[x[..., 4] > conf_thres]  # confidence\n",
    "\n",
    "        # If none remain process next image\n",
    "        if not x.shape[0]:\n",
    "            continue\n",
    "\n",
    "        # Compute conf\n",
    "        x[:, 5:] *= x[:, 4:5]  # conf = obj_conf * cls_conf\n",
    "\n",
    "        # Box (center x, center y, width, height) to (x1, y1, x2, y2)\n",
    "        box = xywh2xyxy(x[:, :4])\n",
    "\n",
    "        # Detections matrix nx6 (xyxy, conf, cls)\n",
    "        if multi_label:\n",
    "            i, j = (x[:, 5:] > conf_thres).nonzero(as_tuple=False).T\n",
    "            x = torch.cat((box[i], x[i, j + 5, None], j[:, None].float()), 1)\n",
    "        else:  # best class only\n",
    "            conf, j = x[:, 5:].max(1, keepdim=True)\n",
    "            x = torch.cat((box, conf, j.float()), 1)[conf.view(-1) > conf_thres]\n",
    "\n",
    "        # Filter by class\n",
    "        if classes is not None:\n",
    "            x = x[(x[:, 5:6] == torch.tensor(classes, device=x.device)).any(1)]\n",
    "\n",
    "        # Check shape\n",
    "        n = x.shape[0]  # number of boxes\n",
    "        if not n:  # no boxes\n",
    "            continue\n",
    "        elif n > max_nms:  # excess boxes\n",
    "            # sort by confidence\n",
    "            x = x[x[:, 4].argsort(descending=True)[:max_nms]]\n",
    "\n",
    "        # Batched NMS\n",
    "        c = x[:, 5:6] * max_wh  # classes\n",
    "        # boxes (offset by class), scores\n",
    "        boxes, scores = x[:, :4] + c, x[:, 4]\n",
    "        i = torchvision.ops.nms(boxes, scores, iou_thres)  # NMS\n",
    "        if i.shape[0] > max_det:  # limit detections\n",
    "            i = i[:max_det]\n",
    "\n",
    "        output[xi] = x[i]\n",
    "\n",
    "        if (time.time() - t) > time_limit:\n",
    "            print(f'WARNING: NMS time limit {time_limit}s exceeded')\n",
    "            break  # time limit exceeded\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVloRQUhB58q"
   },
   "outputs": [],
   "source": [
    "input_img = (img.transpose(2,0,1)).astype(np.float32) / 255. # normalize & transpose\n",
    "input_img = torch.from_numpy( input_img ).unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    input_img = input_img.to(\"cuda\")\n",
    "\n",
    "# Get detections\n",
    "with torch.no_grad():\n",
    "    detections = model(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7xG_xJZCFeL"
   },
   "outputs": [],
   "source": [
    "nms_result = non_max_suppression( detections, conf_thres=0.5, iou_thres=0.5 )[0].to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GqE36j0CFVg",
    "outputId": "90a36292-6d78-4082-c106-0b1deafa0fd4"
   },
   "outputs": [],
   "source": [
    "nms_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "zFQ4n9wQB55W",
    "outputId": "2fb0ed0c-175a-4b00-f0d8-03d2ef68d0da"
   },
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "plot_image = img.copy()\n",
    "\n",
    "for (x1, y1, x2, y2, confidence, cls) in nms_result:\n",
    "\n",
    "    class_name = classes[ int(cls) ]\n",
    "\n",
    "    b, g, r = cls_color[class_name]\n",
    "\n",
    "    text = f'{class_name} : {confidence:.2f}'\n",
    "    size, baseline = cv2.getTextSize( text, 4, 0.9, 2 )\n",
    "    cv2.putText( plot_image, text, (int(x2-size[0]), int(y2+size[1])), 4, 0.9, (b, g, r), 2 )\n",
    "\n",
    "    cv2.rectangle( plot_image, (int(x1), int(y1)), (int(x2), int(y2)), (b, g, r), 2 )\n",
    "\n",
    "plt.figure( figsize=(10,10) )\n",
    "plt.imshow( plot_image[..., ::-1] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUou20n0B5y_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "YOLOv3_EXAMPLE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
